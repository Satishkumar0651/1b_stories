{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/satish/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2024-2-22 Python-3.10.12 torch-2.2.0+cu121 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# Load your pre-trained PyTorch face detection model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def find_optimal_safezone(faces, frame_width, frame_height, safe_zone_margin):\n",
    "    # Initialize the safezone at the bottom of the frame\n",
    "    safezone_top = frame_height * (1 - safe_zone_margin)\n",
    "    safezone_bottom = frame_height\n",
    "\n",
    "    # Check if any face bounding boxes intersect with the bottom safezone\n",
    "    for (x1, y1, x2, y2, conf, cls) in faces:\n",
    "        if y2 >= safezone_top:\n",
    "            # A face intersects with the bottom safezone, try the top of the frame instead\n",
    "            safezone_top = 0\n",
    "            safezone_bottom = frame_height * safe_zone_margin\n",
    "            break\n",
    "\n",
    "    # Check if any face bounding boxes intersect with the top safezone\n",
    "    for (x1, y1, x2, y2, conf, cls) in faces:\n",
    "        if y1 <= safezone_bottom:\n",
    "            # A face intersects with the top safezone, no safezone available in this frame\n",
    "            return None  # Or return an empty safezone indication\n",
    "\n",
    "    # Return the safezone coordinates\n",
    "    return [0, safezone_top, frame_width, safezone_bottom]\n",
    "\n",
    "def adjust_safe_zone(faces, original_safe_zone, width, height):\n",
    "    # Define margin for safezone as a percentage of the frame height\n",
    "    safe_zone_margin = 0.15  # Example: 15% of the frame height\n",
    "\n",
    "    # Find an optimal safezone\n",
    "    optimal_safezone = find_optimal_safezone(faces, width, height, safe_zone_margin)\n",
    "    \n",
    "    return optimal_safezone if optimal_safezone else original_safe_zone\n",
    "\n",
    "\n",
    "def subtract_zones(safe, unsafe):\n",
    "    # This function would subtract the unsafe zone from the safe zone\n",
    "    # and return a list of reduced safe zones that do not overlap with the unsafe zone.\n",
    "    # The actual implementation of this function would need to handle geometry calculations.\n",
    "    # For simplicity, this is just a placeholder function.\n",
    "    return [safe]  # Placeholder, return safe zone unchanged\n",
    "\n",
    "def area(zone):\n",
    "    # Calculate the area of a zone defined as [left, top, right, bottom]\n",
    "    return (zone[2] - zone[0]) * (zone[3] - zone[1])\n",
    "    \n",
    "def calculate_safe_zone(frame_width, frame_height):\n",
    "    # Define margins as a percentage of the frame dimensions\n",
    "    margin_width = int(frame_width * 0.05)\n",
    "    margin_height = int(frame_height * 0.05)\n",
    "    # Calculate safezone coordinates\n",
    "    safe_zone_left = margin_width\n",
    "    safe_zone_top = margin_height\n",
    "    safe_zone_right = frame_width - margin_width\n",
    "    safe_zone_bottom = frame_height - int(frame_height * 0.15)  # Adjust the bottom margin if needed\n",
    "    return [safe_zone_left, safe_zone_top, safe_zone_right, safe_zone_bottom]\n",
    "\n",
    "\n",
    "\n",
    "def process_video(video_path, model):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter('output.mp4', fourcc, 20.0, (width, height))\n",
    "\n",
    "    original_safe_zone = calculate_safe_zone(width, height)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detect faces in the frame\n",
    "        faces = process_frame(frame, model, width, height)\n",
    "\n",
    "        # Dynamically adjust the safe zone based on detected faces\n",
    "        safe_zone = adjust_safe_zone(faces, list(original_safe_zone), width, height)\n",
    "\n",
    "        # Convert safe_zone coordinates to integers\n",
    "        safe_zone = [int(coord) for coord in safe_zone]\n",
    "\n",
    "        # Ensure safe_zone has four elements before drawing\n",
    "        if len(safe_zone) == 4:\n",
    "            # Draw the adjusted safe zone\n",
    "            cv2.rectangle(frame, (safe_zone[0], safe_zone[1]), (safe_zone[2], safe_zone[3]), (0, 255, 0), 2)\n",
    "        else:\n",
    "            print(\"Error: safe_zone does not have the expected format or number of elements.\")\n",
    "\n",
    "        # Write the frame with annotations\n",
    "        out.write(frame)\n",
    "\n",
    "    # Release everything when done\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "def scale_coords(img1_shape, coords, img0_shape):\n",
    "    # Calculate the gain (the amount of scaling done to the original image)\n",
    "    gain = min(img1_shape / img0_shape[0], img1_shape / img0_shape[1])\n",
    "    pad = (img1_shape - img0_shape[1] * gain) / 2, (img1_shape - img0_shape[0] * gain) / 2  # Padding added during resize\n",
    "    coords[:, [0, 2]] -= pad[0]  # Remove padding from x-coordinates\n",
    "    coords[:, [1, 3]] -= pad[1]  # Remove padding from y-coordinates\n",
    "    coords[:, :4] /= gain  # Scale bounding box back to original image size\n",
    "    clamp = lambda x: max(min(x, img0_shape[1] - 1), 0)\n",
    "    coords[:, :4] = coords[:, :4].apply_(clamp)  # Clamp coordinates\n",
    "    return coords\n",
    "def process_frame(frame, model, width, height, input_size=640):\n",
    "    # Resize frame to input size expected by the model\n",
    "    frame_resized = cv2.resize(frame, (input_size, input_size))\n",
    "\n",
    "    # Convert the frame to a tensor\n",
    "    frame_tensor = transforms.ToTensor()(frame_resized).unsqueeze(0)\n",
    "\n",
    "    # If CUDA is available, move the tensor to GPU for faster processing\n",
    "    if torch.cuda.is_available():\n",
    "        frame_tensor = frame_tensor.cuda()\n",
    "        model.cuda()\n",
    "\n",
    "    # Get the model predictions\n",
    "    with torch.no_grad():\n",
    "        predictions = model(frame_tensor)\n",
    "\n",
    "    # Filter out predictions with low confidence\n",
    "    predictions = predictions[0][predictions[0][:, 4] > 0.6]\n",
    "\n",
    "    # Scale the bounding box coordinates back to the size of the original frame\n",
    "    scaled_coords = scale_coords(input_size, predictions[:, :4], frame.shape[:2])\n",
    "    predictions[:, :4] = scaled_coords\n",
    "\n",
    "    # Ensure we're handling the tensor format correctly\n",
    "    faces = []\n",
    "    for i in range(predictions.shape[0]):\n",
    "        det = predictions[i].cpu().numpy()\n",
    "        x1, y1, x2, y2, conf, cls = det[:6]\n",
    "        faces.append((x1, y1, x2, y2, conf, int(cls)))\n",
    "\n",
    "    return faces\n",
    "\n",
    "\n",
    "\n",
    "# Replace with the path to your video\n",
    "video_path = '/home/satish/Downloads/ss.mp4'  # Update this with the correct path\n",
    "process_video(video_path, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('py_mlassignment': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca708f91cabaf33642fa7eb1891a6d9a249997cf2245122389d68e0346f286ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
